在学习每一章的时候我希望能认真读几遍章节前的一大段话！

在简单模型中"存储器系统Memory system"是一个线性的字节数组
实际上却不是这样 MemorySystem具有不同容量、成本、访问时间的存储设备的层次结构  注意：层次
CPU寄存器保存的是最常用的数据，靠近CPU的cache-memory则是一个缓冲区，缓存一些数据和指令，这些数据
和指令则是存储在main-memory，而主存缓存则存放在容量更大，慢速磁盘上，这下磁盘同样也是经常被当做
缓冲区域，存放的是通过网络连接，其他机器的磁盘或磁带上的数据。

这一段话介绍了MemorySystem的几个层次结构
#1 CPU寄存器
#2 cache-memory高速缓存存储器
#3 main-memory主存储器
#4 磁盘或磁带

存储器层次结构为什么会对应用程序的性能有巨大的影响？
如果数据存放在#1中，那么指令执行的时候0个周期内就能访问到，如果存放在#2内，则需要4~75个周期
，而存放在#3中，需要上百个周期，若存放在#4中，大约几千万个周期。



#6.1 存储技术#################################################################################
    SRAM和DRAM的区别
     一句话,SRAM更稳定,存取更快,不需要刷新,没有ECC(纠错码),所以消耗更多晶体管,
     密集度更低，更贵，功耗更大。
        SRAM: 应用在高速缓存存储器
        DRAM: 应用在主存,栈缓冲区

    DRAM芯片的组成
     DRAM芯片中单元分成d个supercell(超单元),每个supercell又由w个DRAM单元组成
     所以一个DRAM芯片由dw个DRAM单元组成，存储dw位信息,d=rc,每个supercell分成了
     二维的结构，r行c列。
     信息通过pin(引脚)的外部连接器传递,比如地址引脚和data引脚,这两种引脚在P401-P402图中
     与内存控制器(memory controller)连接。

    内存控制器从DRAM中获取信息的过程
     内存控制器获取(i,j)处的supercell过场,第一步是先通过addr引脚发送行地址i给DRAM芯片，
     然后DRAM将第i行的所有内容复制到一个"内部行缓存区",然后再发送列地址j,最后DRAM从
     行缓冲区复制出超单元中的w位信息发送给内存控制器

    内存模块(memory module)
     DRAM芯片封装在内存模块中,插在主板的扩展槽上。
    
    增强的DRAM
     介绍了各种DRAM

    非易失性存储器(Nonvolatile memory)
    非易失性,指的是关电后依旧保存信息的,书中介绍了:PROM，EPRO，以及最重要的flash memory闪存，SSD

    Bus:连接CPU和Memory
     数据流通过总线(bus)在处理器和DRAM主存之间来往,通过一些叫做"总线事务(bus transaction)"
     实现数据传送,read transaction:从主存传送数据到CPU，write transaction:从CPU传送数据到主存。
     书上405图6-6展示了CPU芯片，I/O桥,主存之间通过两种总线(system bus和memory bus)连接起来
     

     当执行指令 movq A,%rax 将A的内容加载进寄存器中时,发起读事务(read transaction),由三步组成:
     详细过程看书上P406图6-7及其上面一段文字。

    
    磁盘
     市面上分为了机械磁盘和固态硬盘两种。
     #磁盘构造(P408 图6-9 或者 ppt15页)
     一个主轴(spindle)上放置多个盘片(platter),每个盘片有两面涂有磁性记录材料，主轴带动盘片通常按
     5400~15000每分钟转动(转速称为RPM)，主轴侧面还有传动臂带动的读/写头(每个盘片的两面都有)
     一个盘片的一个表面由多个磁道(track),即同心圆组成，每个磁道划分为一组扇区(sector),每个扇区包含
     通常512字节的数据位,扇区之间由间隙(gap)隔开,间隔不存储数据位.

     柱面：所有盘片表面上到主轴中心距离相等的磁道的集合

     #磁盘容量
     磁盘容量计算公式：
     扇区字节数x平均扇区磁道数x表面磁道数x盘片表面数x盘片数
     书中的例子，有一个磁盘，5个盘片，每个扇区512字节，每个面2w磁道，每条磁道300个扇区
     那么磁盘容量=512x300x20000x2x5=30.72GB(10^9)

     注意 磁盘的容量1GB=10^9字节  1TB=10^12字节  而对于RAM容量相关的计量单位则是
     K=2^10，M=2^30，G=2^30，T=2^40
     #磁盘读写
     磁盘读写目标扇区的内容有三个步骤，所以读写的时间组成也是三部分：
     寻道时间(seek time)，旋转时间(rotational latency),传送时间(transfer time)

     首先传动臂控制读/写头 沿着半价方向移动到目标扇区所在的磁道，当时用时通常为3-9ms, max=20ms
     然后等待目标扇区的第一个位随主轴转动到读/写头下,max=60s/RPM
     最后开始读写扇区的内容，这由旋转速度和每条磁道的扇区数目决定,通常等于60s/(RPS*每磁道平均扇区数)

    连接I/O设备
     简单的讲了一下I/O设备通过I/O总线连接到CPU和主存的架构(书上图6-11)

    
    固态硬盘(solid state disk SSD)
     一个SSD由闪存(flash memory)和闪存翻译层(flash translation layer),闪存翻译层的工作与
     磁盘控制器一样,将对逻辑块的请求翻译成对底层物理设备的访问。
     闪存的构造是层级式的:block(B个)>page(P个),即一个闪存由B个blocks组成，每个block由P个pages组成
     通常page大小在512B--4KB, block由32~128pages组成(16~512KB)

     因为设计的原因，每个块所有位初始只能设置为1，数据按page为单位进行读写，只有当page所属block被
     擦除(将所有位设置为1)后才能进行写操作,大约每个块只能进行10w次写操作，不过由于平均磨损逻辑
     (wear leveling)的存在，擦除会被平均分布在所有块，从而最大化每个块的寿命。

#6.2 局部性(locality)##########################################################################
    局部性有两种，1：temporal locality时间局部性，2：spatial locality空间局部性。
    局部性原理：计算机程序倾向于引用物理地址邻近其他最近引用过的数据项的数据项或者时间逻辑上最近引用
    过的数据项本身，换句话说，有良好局部性的程序比局部性差的程序运行更快。


    对程序数据引用的局部性
     来看一个简单的函数即可：
     int sumvec(int v[])
     {
        int i, sum = 0;
        for(i = 0;  i < N; i ++)
            sum += v[i];
        return sum;
     }
     我们说标量sum有好的时间局部性，向量v有良好的空间局部性，因为sum在每次循环迭代中引用了一次
     v的元素是从0开始顺序读取的。

     我们定义像sumvec这样的顺序访问一个向量每个元素的函数，具有stride-k reference pattern
     即步长为k的引用模式(这里的函数是步长为1的引用模式，特别的k=1称为顺序引用模式：sequential r.p.)

     对于更高维的向量，比如二维，局部性原理也解释了为什么双重嵌套循环要按照"行优先顺序"(row-major order)
     进行读取了。假设v[N][N],如果是按行优先那么引用模式为stride-1,而如果是列优先，则为stride-N。

    取指令的局部性
     如果是初次接触计算机底层原理的读者，一定会好奇为什么取指令也会有局部性，这是因为程序指令是存放在
     内存中的，CPU必须要先取出这些指令。
     如上面的sumvec函数的指令是按照连续的内存顺序执行，所以循环体(循环体的指令)有良好的空间局部性和
     时间局部性。
     
     对于取指令来说，循环有好的时间和空间局部性，循环体越小，局部性越好。

#6.3存储器层次结构与缓存 Caching in the memory hierarchy##########################################
     存储器层次结构
        因为存储技术的原因，CPU和主存之间的速度差距在不断增大,现代计算机系统使用"存储器层次结构"的方法
        图6-21金字塔形,提出了缓存(cashe)这个概念。
        memory hierarchy：寄存器>L1高速缓存>L2高速缓存>L3高速缓存>主存>本地二级存储>远程二级存储
        个人总结一下大体就是：由于CPU和主存的访问时间差异巨大，我们可以将存放在靠近塔底的一些使用过或者说
        待使用的数据存放在靠近塔顶的地方，这样可以用更快的速度访问本应位于更大更慢的底部结构

        csapp课上举了一个生动的例子：
        想象你的书包作为缓存，当你早上起来要上学的时候，在上学之前你要装一些东西进书包，背着书包去上学，
        如果你在学校需要哪些东西就可以从书包里拿出来，而不是每次要用到某样东西都必须走回家拿再带回学校。
        这就是缓存的概念。

        这样做的理由是"局部性原理"
        存储器层次结构创造了一个巨大的存储池,成本与底部的廉价存储池接近，但是以顶部的快速存储池的速度
        访问。
    
####cache(很重要!!!!)########################################################################################
        一个cache有S个cache set,每个cache set有E个cache line,每个cache line又由三部分组成：
        按排放顺序从高位到低位以此是  valid bit---tag bit---cache block
        有效位valid bit只有一位，记录该行是否包含有意义的信息;
        标记位tag bit,有t位(t=m-b-s) 用于跟地址的tag位比对以找到对应的cache line
        数据块cache block,有B位(2^b) 存储真正要缓存的内存地址中的数据
         ____________________________
        |valid__tag____cache block___|
        注意上述的m是这个系统下存储器地址的最大位数m位，形成M=2^m个不同的地址

        看完了cache的构成,我们来解读一下计算机是怎么"读"一个地址的？
        一个m位的address的构成跟这个计算机系统上的cache的组成是有关联的
        cache确定了参数:S=2^s，B=2^b, E,而计算机读一个地址就是按照(从高位到低位)：
              t bits    s bits      b bits
              Tag----Set index----Block offset
        让我们来解释一下各个部分的意义：
        如何寻找cache中的缓存？
        当一条指令告诉CPU要从主存中地址为A的地方读一个数据时,CPU会首先在cache中寻找是否有缓存
        这段地址处的数据。
        首先,从s位的Set index读出这段数据应该存储在哪一个cache set；
        然后，t位的Tag就告诉计算机这段数据存放在该cache set的哪一个cache line(比对Tag)
        最后检查是否设置cache line的valid bit
        读取成功后则按照block offset在B个字节的数据块中读取数据
    
      E=1时：direct-mapped cache
        float dotprod(float x[8], float y[8])
        {
            float sum = 0.0;
            int i;
            for (i = 0; i < 8; i++)
            sum += x[i] * y[i];
            return sum;
        }
        乍一看这个函数具有良好的空间局部性，因此我们认为它的命中率比较高，实际上呢？    
        设浮点数4个字节，一个cache block是16个字节，x被加载到从0开始的32字节连续内存中
        那么可以计算出：m=6,b=4,s=1,t=1  所以address:1位tag 1位组索引 4位块偏移
        查看x和y元素地址对应的组索引可以发现：
        元素    地址高二位   分配cache set    元素    地址高二位   分配cache set
        x[0]        00           0           y[0]        10           0       
        x[1]        00           0           y[1]        10           0
        x[2]        00           0           y[2]        10           0
        x[3]        00           0           y[3]        10           0
        x[4]        01           1           y[4]        11           1
        x[5]        01           1           y[5]        11           1
        x[6]        01           1           y[6]        11           1
        x[7]        01           1           y[7]        11           1
        也就是说每一次计算sum+=x[i]*y[i]的时候，x[i]和y[i]即使是在同一个cache set但是由于tag位
        不一样导致每次都是缓存不命中，我们称这样在x和y的块之间抖动(thrash),即cache反复地loading
        和evicting相同的cache set中的cache blocks
        一个很简单的修正thrash problem的方法是在每个数组结尾放B字节的填充，比如将数组x定义修改为
        float x[8]； ->   float x[12],这样就可以错开x[i],y[i]分配的cache set了，使命中率达到75%

        P432旁注解释了为什么要将组索引位放在中间，而不是高位或者低位，这也是为了局部性(空间局部性)。
      E=2时：E-way Set Associative Caches
        上述只是E=1时的比较简单的直接映射cache,现在讨论E≠1的情况。
        冲突不命中(conflict miss)的原因源自每个cache set中只有一行cache line, Set Associative Caches
        则放宽了这个限制。

        组选择与E=1的情况是一样的，
        
        缓存不命中时的cache line替换策略
        最简单的就是随机选择要替换的行，而最不常使用LFU(Least-Frequently-Used)和最近最少使用LRU
        (Least-Recently-Used)策略利用了局部性原理，但同时也需要额外的时间和硬件。

      Fully associative cache
        也就是只有一个cache set的cache架构,此时地址中没有set index, 因为cache电路要并行的搜索匹配的
        tag, 构造一个又大又快的associative cache很困难且昂贵，所以Fully的只适合做小的cache,例如TLB。
    写操作
      有关写操作是很复杂的(实际上只是读操作比较简单),这里只是简单的介绍有哪些。
      写操作分为 write-hit 和 write-miss, write hit就是说写入地址存在于cache里，如果不在
      就是write miss
      对main memory的修改是昂贵的，写命中和写不命中又细分了两种：
       write-hit
       最简单的方式是write through：将数据同时更新到缓存和内存中
       另一个策略是write back(也被称为write deferred):先只更新cache中的数据，直到修改的内容在cache中
       即将被替换才修改主存的数据。
       我认为正是因为对主存的操作是昂贵的，所以才会设计出write-back这种模式，尽可能减少对主存数据的修改。

       查阅资料后：write-through适用于没有频繁写入缓存的情况,有助于数据恢复，因为存储在cache中的数据在断电或系统故障后难以恢复，
       而write-back需要cache额外维护一位"dirty bit"用来记录缓存中存在的数据是否被修改。
       (https://zhuanlan.zhihu.com/p/571429282)

      write-miss
      write-allocation(也叫做fetch on write)，这种情况下，先将要修改的存放于memory的数据写到cache中
      再更新cache中的cache block
      not-write-allocatio，直接将数据写入主存而不影响缓存。

      write-through通常是not-write-allocatio的，而write-back通常是write-allocatio的

    Real Cache Hierarchy
    实际上的cache既保存了数据又保存了指令
    i-cache：只保存了指令的cache
    d-cache：只保存了数据的cache
    unified cache：既保存数据又保存指令的cache

    为什么要设计独立的两种cache呢，好处在于使用不同的cache不会使数据访问和指令访问形成冲突不命中
    但是坏处在于可能引起容量不命中。

#6.4(csapp6.5和6.6)小结###########################################################################
  Cache-friendly code
    总结就是以下几点：
    #1应该更加关注循环体内的代码
    #2局部变量缓存再寄存器中，对局部变量的反复引用是好的
    #3 stride-1的引用模式是好的，能够很好的利用空间局部性
    有几个练习在书上需要完成(见Book practice)
  
  后面的内容明天再说/滑稽  (2024/2/21)