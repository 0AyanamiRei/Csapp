"到目前为止，我们把内存理解为一个连续的物理字节数组，可以通过给出一些称为'地址'的偏移来访问，所以在使用物理寻址的系统中，CPU执行一条移动指令
生成一个有效的物理地址，这个地址实际上是主存储器中一个字节的偏移量，然后内存从该地址获取其中保存的word，将其发送回CPU，但是我们常见的系统
对主存储器进行虚拟化，虚拟化的概念在CS中是非常重要的，它扩展了很多，应用于计算机系统的很多领域，当你虚拟化一个资源，你向该资源的用户显示该
资源的一些不同类型的视图，你通常会呈现某种抽象或某种不同的资源视图，你可以通过介入对该资源的访问过程来实现这一点，所以当你有一些资源，并且
想要虚拟化它时，你通过干预或介入对该资源的访问过程来实现这一点，然后一旦你····，我们在为函数创建包装函数的时候看到了这一点， 相同的技术可以
用来虚拟化资源，一旦你拦截了访问的过程，那么你就可以用任何你想要的方式处理它，这样你就有很多方法改变那个资源对用户的视图，我们看待磁盘的方式
就是一个很好的例子，磁盘控制器显示的视图实际上并没有柱面、磁道、盘面等信息，它是磁盘的虚拟化视图，而磁盘控制器则将磁盘抽象成一系列逻辑块的
形式提供给内核，它通过拦截来自内核的读写请求来呈现该视图，并将内核发送的逻辑块号转换为实际的物理地址"

CMU15-213 2015 lecture17开篇三分钟 David老师的这段话醍醐灌顶，形象的告诉了我们虚拟化这个技术。

这一节，我采用不同的笔记方式，只记录自己的感想和理解，而不是缓存书上的内容(233)

1、关于9.3第一段话的理解
   虚拟内存是放在磁盘上的memory block，就是一块一块的，只是我们把一块取名叫"VP":virtual page 然后这些VP则缓存在DRAM,
   也就是主存上，回想一下存储层次结构，在DRAM中，我们熟悉的cache block被取名叫"PP":physics page 顿时，第六章存储器层次结构中
   讲cache的部分就浮现在了脑中，虚拟内存用作缓存的工具无非就是大一点的cache~

2、关于9.3.1提到的"由于大的不命中处罚,DRAM缓存是全相联的,即任何VP都能放置在任何PP上"
    我们已经知道虚拟内存的缓存就是磁盘到DRAM的缓存，如果一个cache conflict miss了(有没有想起cache lab的痛苦···), 那么我们需要选择驱逐出去的块
    如果不久的未来我们又使用到驱逐出去的数据，那么我们就会付出很大的代价去caching它，所以我们使用全相联的cache，即S=1，只有一个组，这样尽可能减少
    conflict miss的出现, ok好吧，解释的这些只能说明为什么选择花费更大的替换策略而不是简单的替换策略
    询问copilot后我们发现：
    · 灵活的数据放置，全相联缓存可以减少因为缓存行已满而导致的缓存不命中
    · 避免冲突不命中，对于其他类型的缓存，不同的数据块可能会映射到同一个缓存行，导致conflict miss
    · 优化替换策略， 全相联缓存可以使用更复杂的替换策略，比如LRU，能进一步减少缓存不命中的可能性
3、疏通一下对于VP的Page Hits(cache hit)和Page Faults(cache miss)过程，因为读的时候比较绕，而且由于历史问题，命令上和cache不太一样
    假设CPU想要读VP2这个虚拟页, 首先, 地址翻译硬件通过虚拟地址来定位page table中的PTE2, 然后检查PTE2的valid bit是否设置
    如果设置那么我们称page hits, 如果没有被设置，我们称page faults
    如果是page hits, PTE2中存放有指向DRAM的地址，这个地址处的数据就是我们缓存的VP2
    如果是page faults, 那么触发一个page fault exception(坏了，设计到异常了), 然后调用内核中的"缺页异常处理程序", 通过这个程序
    选择一个victim page, 被选择的page如果被修改则会复制会磁盘中，接下来，内核会从磁盘中复制VP2的内容到DRAM中,然后该处理程序返回
    重启导致page faults的指令，重新将VP2的虚拟地址发送给地址翻译硬件, 然后就是page hits的过程了。
    评价一下：
            跟cache hit和cache miss还是很相似的，只是这里涉及了异常与异常处理，更详细了.

4、csapp中译第565页说了在VM中blcok被称为page, 那么swapping和paging的一些操作对应cache的什么呢？？
    block<----->page
    Caching?<----->Swapping/Paging
    Load?<----->Page In
    Victim?<----->Page Out
    page in指的是将未缓存的数据从硬盘调入DRAM的过程；
    page out指当DRAM的空间不足时候，os选择性地将DRAM中的数据移出，存储到硬盘的虚拟内存区域的过程
    个人感觉有点类似cache中提到的load(加载)和victim(驱逐)吧····


5、有关使用多级页表减少内存要求的一些疑惑， 在我看来就是可以"惰性"的去创建页面并缓存
    书上提到了"只有一级页表才需要总是在主存中，虚拟内存系统可以在需要时创建、page in、page out二级页表"
    “只有最经常使用的那些2级页表才需要缓存在主存中”, 那我只使用一级页表，也按这种的模式不是可以起到同样的效果吗



6、结合了SRAM缓存和TLB加速以及多级页表后开始对地址翻译的过程感到混淆，所以我们这里根据9.6.4的假设来走一遍过程
    


7、关于memory mapping, 名词概念看的我很糊涂，这里集中写一下自己对这些名词的理解吧
    ·区域 linux将VM分成一块一块的areas(or segments), 一个areas由一些连续的VM pages组成，VM pages是VM的基本单元
    通常大小为4KB, 操作系统通过page table将VM中的pages映射到PM中的pages。
    
    ·memory mapping, 有了areas的概念后, 我们说操作系统将一个VM的areas和一个磁盘上的对象(object)关联起来以初始化这片
    areas的内容的过程就叫做内存映射

    ·紧跟着介绍了VM的areas可以映射到Linux中的普通文件和匿名文件。

    ·Regular file: 区别于director文件、symbol link文件、device文件, 指的是包含任意数据的普通文件
    ·匿名文件：cs中通常指没有名字或路径的文件，通常存在内存中，也被称为临时文件，进程的/proc/[pid]/maps文件会列出
    这个进程映射的所有内存areas，包括匿名文件

    







    