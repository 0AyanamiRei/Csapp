"到目前为止，我们把内存理解为一个连续的物理字节数组，可以通过给出一些称为'地址'的偏移来访问，所以在使用物理寻址的系统中，CPU执行一条移动指令
生成一个有效的物理地址，这个地址实际上是主存储器中一个字节的偏移量，然后内存从该地址获取其中保存的word，将其发送回CPU，但是我们常见的系统
对主存储器进行虚拟化，虚拟化的概念在CS中是非常重要的，它扩展了很多，应用于计算机系统的很多领域，当你虚拟化一个资源，你向该资源的用户显示该
资源的一些不同类型的视图，你通常会呈现某种抽象或某种不同的资源视图，你可以通过介入对该资源的访问过程来实现这一点，所以当你有一些资源，并且
想要虚拟化它时，你通过干预或介入对该资源的访问过程来实现这一点，然后一旦你····，我们在为函数创建包装函数的时候看到了这一点， 相同的技术可以
用来虚拟化资源，一旦你拦截了访问的过程，那么你就可以用任何你想要的方式处理它，这样你就有很多方法改变那个资源对用户的视图，我们看待磁盘的方式
就是一个很好的例子，磁盘控制器显示的视图实际上并没有柱面、磁道、盘面等信息，它是磁盘的虚拟化视图，而磁盘控制器则将磁盘抽象成一系列逻辑块的
形式提供给内核，它通过拦截来自内核的读写请求来呈现该视图，并将内核发送的逻辑块号转换为实际的物理地址"

CMU15-213 2015 lecture17开篇三分钟 David老师的这段话醍醐灌顶，形象的告诉了我们虚拟化这个技术。

这一节，我采用不同的笔记方式，只记录自己的感想和理解，而不是缓存书上的内容(2333)

1、关于9.3第一段话的理解
   虚拟内存是放在磁盘上的memory block，就是一块一块的，只是我们把一块取名叫"VP":virtual page 然后这些VP则缓存在DRAM,
   也就是主存上，回想一下存储层次结构，在DRAM中，我们熟悉的cache block被取名叫"PP":physics page 顿时，第六章存储器层次结构中
   讲cache的部分就浮现在了脑中，虚拟内存用作缓存的工具无非就是大一点的cache~

2、关于9.3.1提到的"由于大的不命中处罚,DRAM缓存是全相联的,即任何VP都能放置在任何PP上"
    我们已经知道虚拟内存的缓存就是磁盘到DRAM的缓存，如果一个cache conflict miss了(有没有想起cache lab的痛苦···), 那么我们需要选择驱逐出去的块
    如果不久的未来我们又使用到驱逐出去的数据，那么我们就会付出很大的代价去caching它，所以我们使用全相联的cache，即S=1，只有一个组，这样尽可能减少
    conflict miss的出现, ok好吧，解释的这些只能说明为什么选择花费更大的替换策略而不是简单的替换策略
    询问copilot后我们发现：
    · 灵活的数据放置，全相联缓存可以减少因为缓存行已满而导致的缓存不命中
    · 避免冲突不命中，对于其他类型的缓存，不同的数据块可能会映射到同一个缓存行，导致conflict miss
    · 优化替换策略， 全相联缓存可以使用更复杂的替换策略，比如LRU，能进一步减少缓存不命中的可能性
    